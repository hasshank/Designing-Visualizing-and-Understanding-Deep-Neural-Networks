{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHnb2DbtuNZO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import deeprl.infrastructure.pytorch_util as ptu\n",
        "\n",
        "from deeprl.infrastructure.rl_trainer import RL_Trainer\n",
        "from deeprl.infrastructure.trainers import BC_Trainer\n",
        "from deeprl.agents.bc_agent import BCAgent\n",
        "from deeprl.policies.loaded_gaussian_policy import LoadedGaussianPolicy\n",
        "import deeprl.policies.MLP_policy as MLP_policy\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "def rel_error(x, y):\n",
        "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
        "\n",
        "def remove_folder(path):\n",
        "  if os.path.exists(path):\n",
        "    print(\"Clearing old results at {}\".format(path))\n",
        "    shutil.rmtree(path)\n",
        "  else:\n",
        "    print(\"Folder {} does not exist yet. No old results to delete\".format(path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bc_base_args_dict = dict(\n",
        "    expert_policy_file = 'deeprl/policies/experts/Hopper.pkl',\n",
        "    expert_data = 'deeprl/expert_data/expert_data_Hopper-v2.pkl',\n",
        "    env_name = 'Hopper-v2',\n",
        "    exp_name = 'test_bc',\n",
        "    do_dagger = True,\n",
        "    ep_len = 1000,\n",
        "    save_params = False,\n",
        "\n",
        "    num_agent_train_steps_per_iter = 1000,\n",
        "    n_iter = 1,\n",
        "\n",
        "    batch_size = 1000,\n",
        "    eval_batch_size = 1000,\n",
        "    train_batch_size = 100,\n",
        "    max_replay_buffer_size = 1000000,\n",
        "\n",
        "    n_layers = 2,\n",
        "    size = 64,\n",
        "    learning_rate = 5e-3,\n",
        "\n",
        "    video_log_freq = -1,\n",
        "    scalar_log_freq = 1,\n",
        "\n",
        "    no_gpu = False,\n",
        "    which_gpu = 0,\n",
        "    seed = 2,\n",
        "    logdir = 'test',\n",
        ")"
      ],
      "metadata": {
        "id": "hpVMS1tZvJM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "ac_dim = 2\n",
        "ob_dim = 3\n",
        "batch_size = 5\n",
        "\n",
        "policy = MLPPolicySL(\n",
        "    ac_dim=ac_dim,\n",
        "    ob_dim=ob_dim,\n",
        "    n_layers=1,\n",
        "    size=2,\n",
        "    learning_rate=0.25)\n",
        "\n",
        "np.random.seed(0)\n",
        "obs = np.random.normal(size= (batch_size, ob_dim))\n",
        "actions = np.random.normal(size = (batch_size, ac_dim))\n",
        "\n",
        "first_weight_before = np.array(ptu.to_numpy(next(policy.mean_net.parameters())))\n",
        "print(\"Weight before update\", first_weight_before)\n",
        "\n",
        "for i in range(5):\n",
        "  loss = policy.update(obs, acts)['Training Loss']\n",
        "\n",
        "print(loss)\n",
        "expected_loss = 2.628419\n",
        "loss_error = rel_error(loss, expected_loss)\n",
        "print(\"Loss Error\", loss_error, \"should be on the order of 1e-6 or lower\")\n",
        "\n",
        "first_weight_after = ptu.to_numpy(next(policy.mean_net.parameters()))\n",
        "print(\"Weight after update\", first_weight_after)\n",
        "\n",
        "weight_change = first_weight_after - first_weight_before\n",
        "print(\"Change in weights\", weight_change)\n",
        "\n",
        "expected_change = np.array([[ 0.04385546, -0.4614172,  -1.0613215 ],\n",
        "                            [ 0.20986436, -1.2060736,  -1.0026767 ]])\n",
        "updated_weight_error = rel_error(weight_change, expected_change)\n",
        "print(\"Weight Update Error\", updated_weight_error, \"should be on the order of 1e-6 or lower\")"
      ],
      "metadata": {
        "id": "6kfjw8gzwYMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_args = dict(bc_base_args_dict)\n",
        "\n",
        "env_str = 'HalfCheetah'\n",
        "bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n",
        "bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n",
        "bc_args['env_name'] = '{}-v2'.format(env_str)\n",
        "\n",
        "remove_folder('logs/behaviors_cloning/{}'.format(env_str))\n",
        "\n",
        "for seed in range(3):\n",
        "  print(\"Running behavior cloning experiment with seed\", seed)\n",
        "  bc_args['seed'] = seed\n",
        "  bc_args['logdir'] = 'logs/behaviors_cloning/{}/seed_{}'.format(env_str, seed)\n",
        "  bc_trainer = BC_Trainer(bc_args)\n",
        "  bc_trainer.run_training_loop()"
      ],
      "metadata": {
        "id": "nCKamAlBx9CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/behavior_cloning/HalfCheetah"
      ],
      "metadata": {
        "id": "yd1wEtWAyrsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_args = dict(bc_base_args_dict)\n",
        "\n",
        "env_str = 'Hopper'\n",
        "bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n",
        "bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n",
        "bc_args['env_name'] = '{}-v2'.format(env_str)\n",
        "\n",
        "remove_folder('logs/behavior_cloning/{}'.format(env_str))\n",
        "\n",
        "for seed in range(3):\n",
        "  print(\"Running behavior cloning experiment on Hopper with seed\", seed)\n",
        "  bc_args['seed'] = seed\n",
        "  bc_args['logdir'] = 'logs/behavior_cloning/{}/seed{}'.format(env_str, seed)\n",
        "  bctrainer = BC_Trainer(bc_args)\n",
        "  bctrainer.run_training_loop()"
      ],
      "metadata": {
        "id": "QQD-yBycyx9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard -- logdir logs/behavior_cloning/Hopper"
      ],
      "metadata": {
        "id": "SUw-Si9Wzhww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bc_args = dict(bc_base_args_dict)\n",
        "\n",
        "env_str = 'Hopper'\n",
        "bc_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n",
        "bc_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n",
        "bc_args['env_name'] = '{}-v2'.format(env_str)\n",
        "bctrainer = BC_Trainer(bc_args)\n",
        "\n",
        "np.random.seed(0)\n",
        "T = 2\n",
        "ob_dim = 11\n",
        "ac_dim = 3\n",
        "\n",
        "paths = []\n",
        "for i in range(3):\n",
        "  obs = np.random.normal(size=(T, ob_dim))\n",
        "  acs = np.random.normal(size=(T, ac_dim))\n",
        "  paths.append(dict(observations=obs,\n",
        "                    action=acs))\n",
        "\n",
        "rl_trainer = bctrainer.rl_trainer\n",
        "relabeled_paths = rl_trainer.do_relabel_with_expert(bctrainer.loaded_expert_policy, paths)\n",
        "\n",
        "expert_actions = np.array([[[-1.7814021, -0.11137983,  1.763353  ],\n",
        "                            [-2.589222,   -5.463195,    2.4301376 ]],\n",
        "                           [[-2.8287444, -5.298558,   3.0320463],\n",
        "                            [ 3.9611065,  2.626403,  -2.8639293]],\n",
        "                           [[-0.3055225,  -0.9865407,   0.80830705],\n",
        "                            [ 2.8788857,   3.5550566,  -0.92875874]]])\n",
        "\n",
        "for i, (path, relabeled_path) in enumerate(zip(paths, relabeled_paths)):\n",
        "  assert np.all(path['observation'] == relabeled_path['observation'])\n",
        "  print(\"Path {} expert action error\".format(i), rel_error(expert_actions[i], relabeled_path['action']))\n"
      ],
      "metadata": {
        "id": "RUCOTvtmzmq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dagger_args = dict(bc_base_args_dict)\n",
        "\n",
        "dagger_args['do_dagger'] = True\n",
        "dagger_args['n_iter'] = 10\n",
        "\n",
        "env_str = 'Hopper'\n",
        "dagger_args['expert_policy_file'] = 'deeprl/policies/experts/{}.pkl'.format(env_str)\n",
        "dagger_args['expert_data'] = 'deeprl/expert_data/expert_data_{}-v2.pkl'.format(env_str)\n",
        "dagger_args['env_name'] = '{}-v2'.format(env_str)"
      ],
      "metadata": {
        "id": "9JRsYZ_W1DUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_folder('logs/dagger/{}'.format(env_str))\n",
        "\n",
        "for seed in range(3):\n",
        "  print(\"Running Dagger experiment with seed\", seed)\n",
        "  dagger_args['seed'] = seed\n",
        "  dagger_args['logdir'] = 'logs/dagger/{}/seed_{}'.format(env_str, seed)\n",
        "  bctrainer = BC_Trainer(dagger_args)\n",
        "  bctrainer.run_training_loop()"
      ],
      "metadata": {
        "id": "hGnJgUyv1V9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/dagger/Hopper"
      ],
      "metadata": {
        "id": "kBetFq-H1oLM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}